name: PR Bench Command

on:
  issue_comment:
    types: [created]

permissions:
  contents: read
  issues: write
  pull-requests: write

jobs:
  bench:
    if: github.event.issue.pull_request != null && contains(github.event.comment.body, '/bench')
    runs-on: ubuntu-latest
    env:
      DB_DSN: ${{ secrets.DB_DSN }}
      DB_USER: ${{ secrets.DB_USER }}
      DB_PASS: ${{ secrets.DB_PASS }}
      BENCH_P95_WARN: ${{ vars.BENCH_P95_WARN || '200' }}
      BENCH_P95_FAIL: ${{ vars.BENCH_P95_FAIL || '300' }}
    steps:
      - name: Extract PR head ref
        id: pr
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const prnum = context.issue.number;
            const pr = await github.rest.pulls.get({owner, repo, pull_number: prnum});
            core.setOutput('ref', pr.data.head.ref);
            core.setOutput('sha', pr.data.head.sha);

      - name: Checkout PR head
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.pr.outputs.ref }}
          fetch-depth: 0

      - name: Setup PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: '8.2'
          extensions: pdo_mysql, pdo_pgsql
          tools: none
          coverage: none

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install matplotlib
        run: pip install matplotlib

      - name: Parse /bench args (with presets)
        id: args
        env:
          COMMENT_BODY: ${{ github.event.comment.body }}
        shell: bash
        run: |
          BODY="$COMMENT_BODY"
          MODE="select"
          CONCURRENCY=4
          DURATION=30
          TABLE="bench_items"
          # presets
          if echo "$BODY" | grep -qi "bench quick"; then
            CONCURRENCY=2
            DURATION=10
          fi
          if echo "$BODY" | grep -qi "bench heavy"; then
            CONCURRENCY=16
            DURATION=120
          fi
          # explicit params override presets
          for tok in $BODY; do
            case "$tok" in
              mode=*) MODE="${tok#mode=}";;
              concurrency=*) CONCURRENCY="${tok#concurrency=}";;
              duration=*) DURATION="${tok#duration=}";;
              table=*) TABLE="${tok#table=}";;
              p95warn=*) echo "P95_WARN=${tok#p95warn=}" >> $GITHUB_OUTPUT ;;
              p95fail=*) echo "P95_FAIL=${tok#p95fail=}" >> $GITHUB_OUTPUT ;;
            esac
          done
          echo "mode=$MODE" >> $GITHUB_OUTPUT
          echo "concurrency=$CONCURRENCY" >> $GITHUB_OUTPUT
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          echo "table=$TABLE" >> $GITHUB_OUTPUT

      - name: Run Bench
        shell: pwsh
        run: |
          pwsh ./scripts/bench/Run-Bench.ps1 `
            -Dsn "$env:DB_DSN" -User "$env:DB_USER" -Pass "$env:DB_PASS" `
            -Mode "${{ steps.args.outputs.mode }}" `
            -Concurrency ${{ steps.args.outputs.concurrency }} `
            -Duration ${{ steps.args.outputs.duration }} `
            -Table "${{ steps.args.outputs.table }}" `
            -OutDir ./bench/results

      - name: Plot & Summary
        run: |
          python3 scripts/bench/Bench-Plot.py --glob "bench/results/*.csv" --outdir bench/plots

      - name: Evaluate SLO (p95)
        id: slo
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            const warnEnv = process.env.BENCH_P95_WARN || '200';
            const failEnv = process.env.BENCH_P95_FAIL || '300';
            const warn = parseInt(core.getInput('P95_WARN') || warnEnv);
            const fail = parseInt(core.getInput('P95_FAIL') || failEnv);
            let p95 = 0, avg = 0, total=0, err=0;
            try {
              const m = JSON.parse(fs.readFileSync(path.join(process.cwd(), 'bench/plots/metrics.json'), 'utf8'));
              p95 = m.p95|0; avg = m.avg|0; total = m.total|0; err = m.err|0;
            } catch (e) {}
            core.setOutput('p95', String(p95));
            core.setOutput('avg', String(avg));
            core.setOutput('warn', String(warn));
            core.setOutput('fail', String(fail));
            let verdict = 'pass';
            if (p95 > warn) verdict = 'warn';
            if (p95 > fail) verdict = 'fail';
            core.setOutput('verdict', verdict);

      - name: Label PR if bench regression
        if: github.event.issue.pull_request != null && steps.slo.outputs.verdict == 'fail'
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            try {
              await github.rest.issues.addLabels({owner, repo, issue_number, labels: ['bench:regression']});
            } catch (e) { core.warning('Failed to add bench:regression: ' + e.message); }

      - name: Remove bench:regression label if recovered
        if: github.event.issue.pull_request != null && steps.slo.outputs.verdict != 'fail'
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            try {
              await github.rest.issues.removeLabel({owner, repo, issue_number, name: 'bench:regression'});
            } catch (e) { core.info('No bench:regression to remove'); }

      - name: Upload bench artifacts
        uses: actions/upload-artifact@v4
        with:
          name: bench-${{ steps.pr.outputs.sha }}
          path: |
            bench/results/**
            bench/plots/**

      - name: Comment PR with bench results
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const runId = context.runId;
            const artifactPage = `https://github.com/${owner}/${repo}/actions/runs/${runId}`;
            let summary = '';
            try { summary = fs.readFileSync('bench/plots/SUMMARY.md', 'utf8'); } catch (e) {}
            const v = '${{ steps.slo.outputs.verdict }}';
            const p95 = '${{ steps.slo.outputs.p95 }}';
            const warn = '${{ steps.slo.outputs.warn }}';
            const fail = '${{ steps.slo.outputs.fail }}';
            const badge = v === 'fail' ? 'ðŸ”´ FAIL' : (v === 'warn' ? 'ðŸŸ¡ WARN' : 'ðŸŸ¢ PASS');
            const lines = [
              '<!-- bench-report -->',
              `### ðŸ§ª Bench Results (${badge})`,
              'Mode: \\`${{ steps.args.outputs.mode }}\\`, ' +
                'Concurrency: \\`${{ steps.args.outputs.concurrency }}\\`, ' +
                'Duration: \\`${{ steps.args.outputs.duration }}s\\`',
              '',
              `**p95:** \\`${p95} ms\\` (warn=${warn}, fail=${fail})`,
              '',
              `**Artifacts:** [Run Artifacts Page](${artifactPage})`,
              '',
              '<details><summary>Summary</summary>',
              '',
              '```text',
              summary || 'No summary',
              '```',
              '',
              '</details>'
            ];
            const body = lines.join('\n');
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.body && c.body.includes('<!-- bench-report -->'));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }

      - name: Fail job on regression
        if: steps.slo.outputs.verdict == 'fail'
        run: |
          echo "Bench regression detected: p95=${{ steps.slo.outputs.p95 }} > fail=${{ steps.slo.outputs.fail }}"
          exit 1
