name: PR Bench Auto (quick)

on:
  pull_request:
    types: [opened, reopened, synchronize, ready_for_review]

permissions:
  contents: read
  issues: write
  pull-requests: write

jobs:
  bench_auto:
    if: github.event.pull_request.draft == false
    runs-on: ubuntu-latest
    env:
      DB_DSN: ${{ secrets.DB_DSN }}
      DB_USER: ${{ secrets.DB_USER }}
      DB_PASS: ${{ secrets.DB_PASS }}
      BENCH_P95_WARN: ${{ vars.BENCH_P95_WARN || '200' }}
      BENCH_P95_FAIL: ${{ vars.BENCH_P95_FAIL || '300' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: '8.2'
          extensions: pdo_mysql, pdo_pgsql
          tools: none
          coverage: none

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install matplotlib
        run: pip install matplotlib

      - name: Run Bench (quick preset)
        shell: pwsh
        run: |
          pwsh ./scripts/bench/Run-Bench.ps1 `
            -Dsn "$env:DB_DSN" -User "$env:DB_USER" -Pass "$env:DB_PASS" `
            -Mode "seek" `
            -Concurrency 2 `
            -Duration 10 `
            -Table "bench_items" `
            -OutDir ./bench/results

      - name: Plot & Summary
        run: |
          python3 scripts/bench/Bench-Plot.py --glob "bench/results/*.csv" --outdir bench/plots

      - name: Evaluate SLO (p95)
        id: slo
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            const warn = parseInt(process.env.BENCH_P95_WARN || '200');
            const fail = parseInt(process.env.BENCH_P95_FAIL || '300');
            let p95 = 0, avg = 0, total=0, err=0;
            try {
              const m = JSON.parse(fs.readFileSync(path.join(process.cwd(), 'bench/plots/metrics.json'), 'utf8'));
              p95 = m.p95|0; avg = m.avg|0; total = m.total|0; err = m.err|0;
            } catch (e) {}
            core.setOutput('p95', String(p95));
            core.setOutput('avg', String(avg));
            core.setOutput('warn', String(warn));
            core.setOutput('fail', String(fail));
            let verdict = 'pass';
            if (p95 > warn) verdict = 'warn';
            if (p95 > fail) verdict = 'fail';
            core.setOutput('verdict', verdict);

      - name: Label PR if bench regression
        if: steps.slo.outputs.verdict == 'fail'
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            try { await github.rest.issues.addLabels({owner, repo, issue_number, labels: ['bench:regression']}); }
            catch (e) { core.warning('Failed to add bench:regression: ' + e.message); }

      - name: Remove bench:regression label if recovered
        if: steps.slo.outputs.verdict != 'fail'
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            try { await github.rest.issues.removeLabel({owner, repo, issue_number, name: 'bench:regression'}); }
            catch (e) { core.info('No bench:regression to remove'); }

      - name: Upload bench artifacts
        uses: actions/upload-artifact@v4
        with:
          name: bench-${{ github.sha }}
          path: |
            bench/results/**
            bench/plots/**

      - name: Comment PR with bench results
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const runId = context.runId;
            const artifactPage = `https://github.com/${owner}/${repo}/actions/runs/${runId}`;
            let summary = '';
            try { summary = fs.readFileSync('bench/plots/SUMMARY.md', 'utf8'); } catch (e) {}
            const v = '${{ steps.slo.outputs.verdict }}';
            const p95 = '${{ steps.slo.outputs.p95 }}';
            const warn = '${{ steps.slo.outputs.warn }}';
            const fail = '${{ steps.slo.outputs.fail }}';
            const badge = v === 'fail' ? 'ðŸ”´ FAIL' : (v === 'warn' ? 'ðŸŸ¡ WARN' : 'ðŸŸ¢ PASS');
            const lines = [];
            lines.push('<!-- bench-report -->');
            lines.push(`### ðŸ§ª Bench Results (auto, ${badge})`);
            lines.push('Mode: `select`, Concurrency: `2`, Duration: `10s`');
            lines.push('');
            lines.push(`**p95:** \`${p95} ms\` (warn=${warn}, fail=${fail})`);
            lines.push('');
            lines.push(`**Artifacts:** [Run Artifacts Page](${artifactPage})`);
            lines.push('');
            lines.push('<details><summary>Summary</summary>');
            lines.push('');
            lines.push('```text');
            lines.push(summary || 'No summary');
            lines.push('```');
            lines.push('');
            lines.push('</details>');
            const body = lines.join('\n');
            // Update or create a single comment with marker
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.body && c.body.includes('<!-- bench-report -->'));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }

      - name: Fail job on regression
        if: steps.slo.outputs.verdict == 'fail'
        run: |
          echo "Bench regression detected: p95=${{ steps.slo.outputs.p95 }} > fail=${{ steps.slo.outputs.fail }}"
          exit 1
